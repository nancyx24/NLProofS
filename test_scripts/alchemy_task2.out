no change     /n/fs/nlp-abiramg/miniconda3/condabin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda-env
no change     /n/fs/nlp-abiramg/miniconda3/bin/activate
no change     /n/fs/nlp-abiramg/miniconda3/bin/deactivate
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.sh
no change     /n/fs/nlp-abiramg/miniconda3/etc/fish/conf.d/conda.fish
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/Conda.psm1
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/conda-hook.ps1
no change     /n/fs/nlp-abiramg/miniconda3/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.csh
no change     /u/abiramg/.bashrc
No action taken.
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
Global seed set to 1
Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Traceback (most recent call last):
  File "/n/fs/nlp-abiramg/NLProofS/prover/../prover/proof.py", line 29, in __init__
    sent = proof.ident2sent(p)
  File "/n/fs/nlp-abiramg/NLProofS/prover/../prover/proof.py", line 137, in ident2sent
    raise KeyError
KeyError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/n/fs/nlp-abiramg/NLProofS/prover/datamodule.py", line 30, in read_entailmentbank_proofs
    proof = Proof(
  File "/n/fs/nlp-abiramg/NLProofS/prover/../prover/proof.py", line 98, in __init__
    self.proof_steps.append(ProofStep(self, s, strict))
  File "/n/fs/nlp-abiramg/NLProofS/prover/../prover/proof.py", line 33, in __init__
    raise InvalidProofStep
prover.proof.InvalidProofStep

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/n/fs/nlp-abiramg/NLProofS/prover/main.py", line 23, in <module>
    main()
  File "/n/fs/nlp-abiramg/NLProofS/prover/main.py", line 18, in main
    cli = CLI(EntailmentWriter, ProofDataModule, save_config_overwrite=True)
  File "/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/utilities/cli.py", line 566, in __init__
    self._run_subcommand(self.subcommand)
  File "/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/utilities/cli.py", line 837, in _run_subcommand
    fn(**fn_kwargs)
  File "/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 848, in validate
    return self._call_and_handle_interrupt(self._validate_impl, model, dataloaders, ckpt_path, verbose, datamodule)
  File "/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 721, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 895, in _validate_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1172, in _run
    self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment
  File "/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1490, in _call_setup_hook
    self.datamodule.setup(stage=fn)
  File "/n/fs/nlp-abiramg/NLProofS/prover/datamodule.py", line 446, in setup
    self.ds_val = StepwiseDataset(
  File "/n/fs/nlp-abiramg/NLProofS/prover/datamodule.py", line 265, in __init__
    self.data = read_entailmentbank_proofs(path, is_train)
  File "/n/fs/nlp-abiramg/NLProofS/prover/datamodule.py", line 39, in read_entailmentbank_proofs
    assert is_train
AssertionError
