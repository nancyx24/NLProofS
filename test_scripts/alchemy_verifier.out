no change     /n/fs/nlp-abiramg/miniconda3/condabin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda-env
no change     /n/fs/nlp-abiramg/miniconda3/bin/activate
no change     /n/fs/nlp-abiramg/miniconda3/bin/deactivate
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.sh
no change     /n/fs/nlp-abiramg/miniconda3/etc/fish/conf.d/conda.fish
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/Conda.psm1
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/conda-hook.ps1
no change     /n/fs/nlp-abiramg/miniconda3/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.csh
no change     /u/abiramg/.bashrc
No action taken.
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
Global seed set to 1
Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
slurmstepd: error: *** JOB 18999103 ON node203 CANCELLED AT 2023-05-06T18:25:24 ***
