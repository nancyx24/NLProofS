no change     /n/fs/nlp-abiramg/miniconda3/condabin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda-env
no change     /n/fs/nlp-abiramg/miniconda3/bin/activate
no change     /n/fs/nlp-abiramg/miniconda3/bin/deactivate
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.sh
no change     /n/fs/nlp-abiramg/miniconda3/etc/fish/conf.d/conda.fish
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/Conda.psm1
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/conda-hook.ps1
no change     /n/fs/nlp-abiramg/miniconda3/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.csh
no change     /u/hbgao/.bashrc
No action taken.
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
Global seed set to 1
Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at ./lightning_logs/gsm8k_prover/checkpoints/epoch=499-step=5500.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./lightning_logs/gsm8k_prover/checkpoints/epoch=499-step=5500.ckpt
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 104 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
75 proofs loaded. 0 invalid ones removed.
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/19 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/19 [00:00<?, ?it/s]Testing DataLoader 0:   5%|▌         | 1/19 [00:07<02:06,  7.03s/it]Testing DataLoader 0:   5%|▌         | 1/19 [00:07<02:06,  7.03s/it]Testing DataLoader 0:  11%|█         | 2/19 [00:37<05:56, 20.96s/it]Testing DataLoader 0:  11%|█         | 2/19 [00:37<05:56, 20.96s/it]Testing DataLoader 0:  16%|█▌        | 3/19 [00:49<04:30, 16.91s/it]Testing DataLoader 0:  16%|█▌        | 3/19 [00:49<04:30, 16.91s/it]Testing DataLoader 0:  21%|██        | 4/19 [01:05<04:09, 16.61s/it]Testing DataLoader 0:  21%|██        | 4/19 [01:05<04:09, 16.61s/it]Testing DataLoader 0:  26%|██▋       | 5/19 [01:15<03:17, 14.09s/it]Testing DataLoader 0:  26%|██▋       | 5/19 [01:15<03:17, 14.09s/it]Testing DataLoader 0:  32%|███▏      | 6/19 [01:34<03:26, 15.85s/it]Testing DataLoader 0:  32%|███▏      | 6/19 [01:34<03:26, 15.85s/it]Testing DataLoader 0:  37%|███▋      | 7/19 [01:49<03:04, 15.37s/it]Testing DataLoader 0:  37%|███▋      | 7/19 [01:49<03:04, 15.37s/it]Testing DataLoader 0:  42%|████▏     | 8/19 [01:55<02:15, 12.31s/it]Testing DataLoader 0:  42%|████▏     | 8/19 [01:55<02:15, 12.31s/it]Testing DataLoader 0:  47%|████▋     | 9/19 [02:00<01:40, 10.08s/it]Testing DataLoader 0:  47%|████▋     | 9/19 [02:00<01:40, 10.08s/it]Testing DataLoader 0:  53%|█████▎    | 10/19 [02:06<01:20,  8.98s/it]Testing DataLoader 0:  53%|█████▎    | 10/19 [02:06<01:20,  8.98s/it]Testing DataLoader 0:  58%|█████▊    | 11/19 [02:21<01:26, 10.80s/it]Testing DataLoader 0:  58%|█████▊    | 11/19 [02:21<01:26, 10.80s/it]Testing DataLoader 0:  63%|██████▎   | 12/19 [02:36<01:23, 11.95s/it]Testing DataLoader 0:  63%|██████▎   | 12/19 [02:36<01:23, 11.95s/it]Testing DataLoader 0:  68%|██████▊   | 13/19 [02:44<01:05, 10.96s/it]Testing DataLoader 0:  68%|██████▊   | 13/19 [02:44<01:05, 10.96s/it]Testing DataLoader 0:  74%|███████▎  | 14/19 [02:55<00:53, 10.77s/it]Testing DataLoader 0:  74%|███████▎  | 14/19 [02:55<00:53, 10.77s/it]Testing DataLoader 0:  79%|███████▉  | 15/19 [03:19<00:58, 14.74s/it]Testing DataLoader 0:  79%|███████▉  | 15/19 [03:19<00:58, 14.74s/it]Testing DataLoader 0:  84%|████████▍ | 16/19 [03:33<00:43, 14.58s/it]Testing DataLoader 0:  84%|████████▍ | 16/19 [03:33<00:43, 14.58s/it]Testing DataLoader 0:  89%|████████▉ | 17/19 [03:48<00:29, 14.83s/it]Testing DataLoader 0:  89%|████████▉ | 17/19 [03:48<00:29, 14.83s/it]Testing DataLoader 0:  95%|█████████▍| 18/19 [04:01<00:14, 14.33s/it]Testing DataLoader 0:  95%|█████████▍| 18/19 [04:01<00:14, 14.33s/it]Testing DataLoader 0: 100%|██████████| 19/19 [04:12<00:00, 13.17s/it]Testing DataLoader 0: 100%|██████████| 19/19 [04:12<00:00, 13.17s/it]Validation results saved to /n/fs/nlp-abiramg/NLProofS/prover/lightning_logs/version_19005366/results_test.json and /n/fs/nlp-abiramg/NLProofS/prover/lightning_logs/version_19005366/results_test.tsv

  0%|          | 0/75 [00:00<?, ?it/s][A100%|██████████| 75/75 [00:00<00:00, 2398.01it/s]
Performance by depth:
28 trees have depth 3
	leaves: 0.8214285714285714	0.9697911215768359
	steps: 0.0	0.264484126984127
	proof: 0.0	0.0
30 trees have depth 4
	leaves: 0.7666666666666667	0.9601587301587302
	steps: 0.0	0.18119528619528621
	proof: 0.0	0.0
12 trees have depth 5
	leaves: 0.5833333333333334	0.9288359788359789
	steps: 0.0	0.1021885521885522
	proof: 0.0	0.0
4 trees have depth 6
	leaves: 0.75	0.9722222222222222
	steps: 0.0	0.04545454545454545
	proof: 0.0	0.0
1 trees have depth 7
	leaves: 1.0	1.0
	steps: 0.0	0.0
	proof: 0.0	0.0
Performance by size:
4 trees have size 6
	leaves: 0.75	0.9642857142857143
	steps: 0.0	0.25
	proof: 0.0	0.0
7 trees have size 7
	leaves: 1.0	1.0
	steps: 0.0	0.32653061224489793
	proof: 0.0	0.0
10 trees have size 8
	leaves: 0.8	0.968888888888889
	steps: 0.0	0.21428571428571433
	proof: 0.0	0.0
11 trees have size 9
	leaves: 0.8181818181818182	0.9671717171717172
	steps: 0.0	0.13672438672438672
	proof: 0.0	0.0
9 trees have size 10
	leaves: 1.0	1.0
	steps: 0.0	0.24523809523809526
	proof: 0.0	0.0
7 trees have size 11
	leaves: 0.8571428571428571	0.967032967032967
	steps: 0.0	0.2588538445681303
	proof: 0.0	0.0
7 trees have size 12
	leaves: 0.7142857142857143	0.9591836734693878
	steps: 0.0	0.16859410430839003
	proof: 0.0	0.0
4 trees have size 13
	leaves: 0.5	0.8999999999999999
	steps: 0.0	0.3204545454545455
	proof: 0.0	0.0
5 trees have size 14
	leaves: 0.4	0.8800000000000001
	steps: 0.0	0.05
	proof: 0.0	0.0
3 trees have size 15
	leaves: 0.3333333333333333	0.9153439153439153
	steps: 0.0	0.0606060606060606
	proof: 0.0	0.0
1 trees have size 16
	leaves: 0.0	0.8571428571428571
	steps: 0.0	0.0
	proof: 0.0	0.0
3 trees have size 17
	leaves: 0.6666666666666666	0.9629629629629629
	steps: 0.0	0.0606060606060606
	proof: 0.0	0.0
1 trees have size 18
	leaves: 1.0	1.0
	steps: 0.0	0.22222222222222224
	proof: 0.0	0.0
1 trees have size 21
	leaves: 0.0	0.8333333333333333
	steps: 0.0	0.0
	proof: 0.0	0.0
1 trees have size 22
	leaves: 1.0	1.0
	steps: 0.0	0.0
	proof: 0.0	0.0
1 trees have size 25
	leaves: 1.0	1.0
	steps: 0.0	0.0
	proof: 0.0	0.0
Testing DataLoader 0: 100%|██████████| 19/19 [04:12<00:00, 13.29s/it]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
 ExactMatch_leaves_test            0.76
  ExactMatch_proof_test             0.0
  ExactMatch_steps_test             0.0
     F1_leaves_test         0.9599177859177858
      F1_proof_test                 0.0
      F1_steps_test          0.189993265993266
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Configuration: 
 Namespace(config=None, subcommand='test', test=Namespace(config=[Path_fsr(gsm_task1.yaml, cwd=/n/fs/nlp-abiramg/NLProofS/prover)], seed_everything=1, trainer=Namespace(logger=True, checkpoint_callback=None, enable_checkpointing=True, callbacks=[Namespace(class_path='pytorch_lightning.callbacks.LearningRateMonitor', init_args=Namespace(logging_interval='step', log_momentum=False))], default_root_dir=None, gradient_clip_val=0.5, gradient_clip_algorithm=None, process_position=0, num_nodes=1, num_processes=None, devices=None, gpus=1, auto_select_gpus=False, tpu_cores=None, ipus=None, log_gpu_memory=None, progress_bar_refresh_rate=None, enable_progress_bar=True, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=10, fast_dev_run=False, accumulate_grad_batches=16, max_epochs=500, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, val_check_interval=None, flush_logs_every_n_steps=None, log_every_n_steps=5, accelerator=None, strategy=None, sync_batchnorm=False, precision=32, enable_model_summary=True, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, resume_from_checkpoint=None, profiler=None, benchmark=None, deterministic=False, reload_dataloaders_every_n_epochs=0, auto_lr_find=False, replace_sampler_ddp=True, detect_anomaly=False, auto_scale_batch_size=False, prepare_data_per_node=None, plugins=None, amp_backend='native', amp_level=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False, terminate_on_nan=None), model=Namespace(stepwise=True, max_num_steps=20, model_name='t5-large', lr=0.0001, warmup_steps=1000, diversity_penalty=0, num_beam_groups=1, num_beams=10, topk=10, proof_search=True, verifier_weight=0.5, verifier_ckpt='../verifier/lightning_logs/gsm8k_verifier/checkpoints/epoch=37-step=88730.ckpt', oracle_prover=False, oracle_verifier=False, dataset='entailmentbank', max_input_len=1024, log_name=''), data=Namespace(dataset='entailmentbank', sample_goal='hypothesis', max_input_len=1024, max_output_len=64, batch_size=4, num_workers=2, path_train='../data/train_gsm8k.jsonl', path_val='../data/dev_gsm8k.jsonl', path_test='../data/test_gsm8k.jsonl', subtree_proved_prob=0.5, subtree_proved_all_or_none=True, model_name='t5-large', stepwise=True), log_name='', ckpt_path='./lightning_logs/gsm8k_prover/checkpoints/epoch=499-step=5500.ckpt', verbose=True))
