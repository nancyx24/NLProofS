no change     /n/fs/nlp-abiramg/miniconda3/condabin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda
no change     /n/fs/nlp-abiramg/miniconda3/bin/conda-env
no change     /n/fs/nlp-abiramg/miniconda3/bin/activate
no change     /n/fs/nlp-abiramg/miniconda3/bin/deactivate
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.sh
no change     /n/fs/nlp-abiramg/miniconda3/etc/fish/conf.d/conda.fish
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/Conda.psm1
no change     /n/fs/nlp-abiramg/miniconda3/shell/condabin/conda-hook.ps1
no change     /n/fs/nlp-abiramg/miniconda3/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /n/fs/nlp-abiramg/miniconda3/etc/profile.d/conda.csh
no change     /u/hbgao/.bashrc
No action taken.
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/ete3-3.1.2-py3.7.egg/ete3/evol/parser/codemlparser.py:221: SyntaxWarning: "is" with a literal. Did you mean "=="?
Global seed set to 1
Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 10.5M/1.43G [00:00<00:14, 96.7MB/s]Downloading pytorch_model.bin:   2%|▏         | 31.5M/1.43G [00:00<00:12, 110MB/s] Downloading pytorch_model.bin:   4%|▎         | 52.4M/1.43G [00:00<00:11, 116MB/s]Downloading pytorch_model.bin:   5%|▌         | 73.4M/1.43G [00:00<00:11, 116MB/s]Downloading pytorch_model.bin:   7%|▋         | 94.4M/1.43G [00:00<00:11, 116MB/s]Downloading pytorch_model.bin:   8%|▊         | 115M/1.43G [00:00<00:11, 117MB/s] Downloading pytorch_model.bin:  10%|▉         | 136M/1.43G [00:01<00:10, 117MB/s]Downloading pytorch_model.bin:  11%|█         | 157M/1.43G [00:01<00:10, 116MB/s]Downloading pytorch_model.bin:  13%|█▎        | 178M/1.43G [00:01<00:10, 117MB/s]Downloading pytorch_model.bin:  14%|█▍        | 199M/1.43G [00:01<00:10, 117MB/s]Downloading pytorch_model.bin:  15%|█▌        | 220M/1.43G [00:01<00:10, 117MB/s]Downloading pytorch_model.bin:  17%|█▋        | 241M/1.43G [00:02<00:10, 117MB/s]Downloading pytorch_model.bin:  18%|█▊        | 262M/1.43G [00:02<00:09, 117MB/s]Downloading pytorch_model.bin:  20%|█▉        | 283M/1.43G [00:02<00:09, 117MB/s]Downloading pytorch_model.bin:  21%|██▏       | 304M/1.43G [00:02<00:09, 117MB/s]Downloading pytorch_model.bin:  23%|██▎       | 325M/1.43G [00:02<00:09, 117MB/s]Downloading pytorch_model.bin:  24%|██▍       | 346M/1.43G [00:02<00:09, 117MB/s]Downloading pytorch_model.bin:  26%|██▌       | 367M/1.43G [00:03<00:09, 117MB/s]Downloading pytorch_model.bin:  27%|██▋       | 388M/1.43G [00:03<00:08, 117MB/s]Downloading pytorch_model.bin:  29%|██▊       | 409M/1.43G [00:03<00:08, 117MB/s]Downloading pytorch_model.bin:  30%|███       | 430M/1.43G [00:03<00:08, 117MB/s]Downloading pytorch_model.bin:  32%|███▏      | 451M/1.43G [00:03<00:08, 114MB/s]Downloading pytorch_model.bin:  33%|███▎      | 472M/1.43G [00:04<00:08, 115MB/s]Downloading pytorch_model.bin:  35%|███▍      | 493M/1.43G [00:04<00:08, 115MB/s]Downloading pytorch_model.bin:  36%|███▌      | 514M/1.43G [00:04<00:07, 115MB/s]Downloading pytorch_model.bin:  38%|███▊      | 535M/1.43G [00:04<00:07, 116MB/s]Downloading pytorch_model.bin:  39%|███▉      | 556M/1.43G [00:04<00:07, 115MB/s]Downloading pytorch_model.bin:  40%|████      | 577M/1.43G [00:04<00:07, 113MB/s]Downloading pytorch_model.bin:  42%|████▏     | 598M/1.43G [00:05<00:07, 117MB/s]Downloading pytorch_model.bin:  43%|████▎     | 619M/1.43G [00:05<00:07, 114MB/s]Downloading pytorch_model.bin:  45%|████▍     | 640M/1.43G [00:05<00:06, 116MB/s]Downloading pytorch_model.bin:  46%|████▋     | 661M/1.43G [00:05<00:06, 114MB/s]Downloading pytorch_model.bin:  48%|████▊     | 682M/1.43G [00:05<00:06, 115MB/s]Downloading pytorch_model.bin:  49%|████▉     | 703M/1.43G [00:06<00:06, 114MB/s]Downloading pytorch_model.bin:  51%|█████     | 724M/1.43G [00:06<00:06, 114MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 744M/1.43G [00:06<00:06, 112MB/s]Downloading pytorch_model.bin:  54%|█████▎    | 765M/1.43G [00:06<00:05, 113MB/s]Downloading pytorch_model.bin:  55%|█████▌    | 786M/1.43G [00:06<00:05, 114MB/s]Downloading pytorch_model.bin:  57%|█████▋    | 807M/1.43G [00:07<00:05, 113MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 828M/1.43G [00:07<00:05, 111MB/s]Downloading pytorch_model.bin:  60%|█████▉    | 849M/1.43G [00:07<00:05, 110MB/s]Downloading pytorch_model.bin:  61%|██████    | 870M/1.43G [00:07<00:04, 111MB/s]Downloading pytorch_model.bin:  63%|██████▎   | 891M/1.43G [00:07<00:04, 112MB/s]Downloading pytorch_model.bin:  64%|██████▍   | 912M/1.43G [00:07<00:04, 112MB/s]Downloading pytorch_model.bin:  65%|██████▌   | 933M/1.43G [00:08<00:04, 114MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 954M/1.43G [00:08<00:04, 113MB/s]Downloading pytorch_model.bin:  68%|██████▊   | 975M/1.43G [00:08<00:03, 114MB/s]Downloading pytorch_model.bin:  70%|██████▉   | 996M/1.43G [00:08<00:03, 113MB/s]Downloading pytorch_model.bin:  71%|███████▏  | 1.02G/1.43G [00:08<00:03, 113MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 1.04G/1.43G [00:09<00:03, 111MB/s]Downloading pytorch_model.bin:  74%|███████▍  | 1.06G/1.43G [00:09<00:03, 110MB/s]Downloading pytorch_model.bin:  76%|███████▌  | 1.08G/1.43G [00:09<00:03, 111MB/s]Downloading pytorch_model.bin:  77%|███████▋  | 1.10G/1.43G [00:09<00:02, 110MB/s]Downloading pytorch_model.bin:  79%|███████▊  | 1.12G/1.43G [00:09<00:02, 112MB/s]Downloading pytorch_model.bin:  80%|████████  | 1.14G/1.43G [00:10<00:02, 112MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 1.16G/1.43G [00:10<00:03, 85.4MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 1.18G/1.43G [00:10<00:02, 92.1MB/s]Downloading pytorch_model.bin:  85%|████████▍ | 1.21G/1.43G [00:10<00:02, 98.1MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 1.23G/1.43G [00:10<00:01, 103MB/s] Downloading pytorch_model.bin:  88%|████████▊ | 1.25G/1.43G [00:11<00:01, 107MB/s]Downloading pytorch_model.bin:  89%|████████▉ | 1.27G/1.43G [00:11<00:01, 109MB/s]Downloading pytorch_model.bin:  90%|█████████ | 1.29G/1.43G [00:11<00:01, 112MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 1.31G/1.43G [00:11<00:01, 113MB/s]Downloading pytorch_model.bin:  93%|█████████▎| 1.33G/1.43G [00:11<00:00, 113MB/s]Downloading pytorch_model.bin:  95%|█████████▍| 1.35G/1.43G [00:12<00:00, 111MB/s]Downloading pytorch_model.bin:  96%|█████████▋| 1.37G/1.43G [00:12<00:00, 111MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 1.39G/1.43G [00:12<00:00, 112MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 1.42G/1.43G [00:12<00:00, 113MB/s]Downloading pytorch_model.bin: 100%|██████████| 1.43G/1.43G [00:12<00:00, 112MB/s]
Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 67.8kB/s]
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at ./lightning_logs/scone_prover_train/checkpoints/epoch=499-step=5000.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./lightning_logs/scone_prover_train/checkpoints/epoch=499-step=5000.ckpt
/n/fs/nlp-abiramg/miniconda3/envs/nlproofs/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 104 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
150 proofs loaded. 0 invalid ones removed.
Validation: 0it [00:00, ?it/s]Validation:   0%|          | 0/75 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/75 [00:00<?, ?it/s]Validation DataLoader 0:   1%|▏         | 1/75 [00:34<42:38, 34.57s/it]Validation DataLoader 0:   1%|▏         | 1/75 [00:34<42:38, 34.57s/it]Validation DataLoader 0:   3%|▎         | 2/75 [00:38<19:58, 16.42s/it]Validation DataLoader 0:   3%|▎         | 2/75 [00:38<19:58, 16.42s/it]Validation DataLoader 0:   4%|▍         | 3/75 [00:40<12:10, 10.15s/it]Validation DataLoader 0:   4%|▍         | 3/75 [00:40<12:10, 10.15s/it]Validation DataLoader 0:   5%|▌         | 4/75 [00:42<08:05,  6.84s/it]Validation DataLoader 0:   5%|▌         | 4/75 [00:42<08:05,  6.84s/it]Validation DataLoader 0:   7%|▋         | 5/75 [00:45<06:14,  5.35s/it]Validation DataLoader 0:   7%|▋         | 5/75 [00:45<06:14,  5.35s/it]Validation DataLoader 0:   8%|▊         | 6/75 [00:48<05:16,  4.58s/it]Validation DataLoader 0:   8%|▊         | 6/75 [00:48<05:16,  4.58s/it]Validation DataLoader 0:   9%|▉         | 7/75 [00:52<04:47,  4.22s/it]Validation DataLoader 0:   9%|▉         | 7/75 [00:52<04:47,  4.22s/it]Validation DataLoader 0:  11%|█         | 8/75 [00:53<03:43,  3.34s/it]Validation DataLoader 0:  11%|█         | 8/75 [00:53<03:43,  3.34s/it]Validation DataLoader 0:  12%|█▏        | 9/75 [00:55<03:23,  3.08s/it]Validation DataLoader 0:  12%|█▏        | 9/75 [00:55<03:23,  3.08s/it]Validation DataLoader 0:  13%|█▎        | 10/75 [00:58<03:09,  2.91s/it]Validation DataLoader 0:  13%|█▎        | 10/75 [00:58<03:09,  2.91s/it]Validation DataLoader 0:  15%|█▍        | 11/75 [00:59<02:35,  2.43s/it]Validation DataLoader 0:  15%|█▍        | 11/75 [00:59<02:35,  2.43s/it]Validation DataLoader 0:  16%|█▌        | 12/75 [01:05<03:41,  3.52s/it]Validation DataLoader 0:  16%|█▌        | 12/75 [01:05<03:41,  3.52s/it]Validation DataLoader 0:  17%|█▋        | 13/75 [01:09<03:43,  3.60s/it]Validation DataLoader 0:  17%|█▋        | 13/75 [01:09<03:43,  3.60s/it]Validation DataLoader 0:  19%|█▊        | 14/75 [01:11<03:04,  3.03s/it]Validation DataLoader 0:  19%|█▊        | 14/75 [01:11<03:04,  3.03s/it]Validation DataLoader 0:  20%|██        | 15/75 [01:13<02:54,  2.90s/it]Validation DataLoader 0:  20%|██        | 15/75 [01:13<02:54,  2.90s/it]Validation DataLoader 0:  21%|██▏       | 16/75 [01:16<02:49,  2.87s/it]Validation DataLoader 0:  21%|██▏       | 16/75 [01:16<02:49,  2.87s/it]Validation DataLoader 0:  23%|██▎       | 17/75 [01:18<02:23,  2.47s/it]Validation DataLoader 0:  23%|██▎       | 17/75 [01:18<02:23,  2.47s/it]Validation DataLoader 0:  24%|██▍       | 18/75 [01:20<02:18,  2.43s/it]Validation DataLoader 0:  24%|██▍       | 18/75 [01:20<02:18,  2.43s/it]Validation DataLoader 0:  25%|██▌       | 19/75 [01:23<02:21,  2.52s/it]Validation DataLoader 0:  25%|██▌       | 19/75 [01:23<02:21,  2.52s/it]Validation DataLoader 0:  27%|██▋       | 20/75 [01:24<02:01,  2.20s/it]Validation DataLoader 0:  27%|██▋       | 20/75 [01:24<02:01,  2.20s/it]Validation DataLoader 0:  28%|██▊       | 21/75 [01:27<01:59,  2.21s/it]Validation DataLoader 0:  28%|██▊       | 21/75 [01:27<01:59,  2.21s/it]Validation DataLoader 0:  29%|██▉       | 22/75 [01:28<01:49,  2.07s/it]Validation DataLoader 0:  29%|██▉       | 22/75 [01:28<01:49,  2.07s/it]Validation DataLoader 0:  31%|███       | 23/75 [01:33<02:21,  2.71s/it]Validation DataLoader 0:  31%|███       | 23/75 [01:33<02:21,  2.71s/it]Validation DataLoader 0:  32%|███▏      | 24/75 [01:36<02:28,  2.91s/it]Validation DataLoader 0:  32%|███▏      | 24/75 [01:36<02:28,  2.91s/it]Validation DataLoader 0:  33%|███▎      | 25/75 [01:38<02:14,  2.70s/it]Validation DataLoader 0:  33%|███▎      | 25/75 [01:38<02:14,  2.70s/it]Validation DataLoader 0:  35%|███▍      | 26/75 [01:40<01:55,  2.37s/it]Validation DataLoader 0:  35%|███▍      | 26/75 [01:40<01:55,  2.37s/it]Validation DataLoader 0:  36%|███▌      | 27/75 [01:41<01:40,  2.09s/it]Validation DataLoader 0:  36%|███▌      | 27/75 [01:41<01:40,  2.09s/it]Validation DataLoader 0:  37%|███▋      | 28/75 [01:43<01:29,  1.91s/it]Validation DataLoader 0:  37%|███▋      | 28/75 [01:43<01:29,  1.91s/it]Validation DataLoader 0:  39%|███▊      | 29/75 [01:44<01:15,  1.65s/it]Validation DataLoader 0:  39%|███▊      | 29/75 [01:44<01:15,  1.65s/it]Validation DataLoader 0:  40%|████      | 30/75 [01:45<01:09,  1.55s/it]Validation DataLoader 0:  40%|████      | 30/75 [01:45<01:09,  1.55s/it]Validation DataLoader 0:  41%|████▏     | 31/75 [01:46<00:58,  1.33s/it]Validation DataLoader 0:  41%|████▏     | 31/75 [01:46<00:58,  1.33s/it]Validation DataLoader 0:  43%|████▎     | 32/75 [01:47<00:58,  1.37s/it]Validation DataLoader 0:  43%|████▎     | 32/75 [01:47<00:58,  1.37s/it]Validation DataLoader 0:  44%|████▍     | 33/75 [01:48<00:50,  1.20s/it]Validation DataLoader 0:  44%|████▍     | 33/75 [01:48<00:50,  1.20s/it]Validation DataLoader 0:  45%|████▌     | 34/75 [01:51<01:09,  1.70s/it]Validation DataLoader 0:  45%|████▌     | 34/75 [01:51<01:09,  1.70s/it]Validation DataLoader 0:  47%|████▋     | 35/75 [01:54<01:26,  2.17s/it]Validation DataLoader 0:  47%|████▋     | 35/75 [01:54<01:26,  2.17s/it]Validation DataLoader 0:  48%|████▊     | 36/75 [01:55<01:08,  1.75s/it]Validation DataLoader 0:  48%|████▊     | 36/75 [01:55<01:08,  1.75s/it]Validation DataLoader 0:  49%|████▉     | 37/75 [01:56<01:00,  1.59s/it]Validation DataLoader 0:  49%|████▉     | 37/75 [01:56<01:00,  1.59s/it]Validation DataLoader 0:  51%|█████     | 38/75 [01:57<00:50,  1.35s/it]Validation DataLoader 0:  51%|█████     | 38/75 [01:57<00:50,  1.35s/it]Validation DataLoader 0:  52%|█████▏    | 39/75 [02:00<01:10,  1.96s/it]Validation DataLoader 0:  52%|█████▏    | 39/75 [02:00<01:10,  1.96s/it]Validation DataLoader 0:  53%|█████▎    | 40/75 [02:03<01:12,  2.07s/it]Validation DataLoader 0:  53%|█████▎    | 40/75 [02:03<01:12,  2.07s/it]Validation DataLoader 0:  55%|█████▍    | 41/75 [02:04<01:04,  1.90s/it]Validation DataLoader 0:  55%|█████▍    | 41/75 [02:04<01:04,  1.90s/it]Validation DataLoader 0:  56%|█████▌    | 42/75 [02:05<00:54,  1.65s/it]Validation DataLoader 0:  56%|█████▌    | 42/75 [02:05<00:54,  1.65s/it]Validation DataLoader 0:  57%|█████▋    | 43/75 [02:07<00:56,  1.76s/it]Validation DataLoader 0:  57%|█████▋    | 43/75 [02:07<00:56,  1.76s/it]Validation DataLoader 0:  59%|█████▊    | 44/75 [02:08<00:45,  1.48s/it]Validation DataLoader 0:  59%|█████▊    | 44/75 [02:08<00:45,  1.48s/it]Validation DataLoader 0:  60%|██████    | 45/75 [02:09<00:38,  1.27s/it]Validation DataLoader 0:  60%|██████    | 45/75 [02:09<00:38,  1.27s/it]Validation DataLoader 0:  61%|██████▏   | 46/75 [02:10<00:32,  1.13s/it]Validation DataLoader 0:  61%|██████▏   | 46/75 [02:10<00:32,  1.13s/it]Validation DataLoader 0:  63%|██████▎   | 47/75 [02:11<00:36,  1.31s/it]Validation DataLoader 0:  63%|██████▎   | 47/75 [02:11<00:36,  1.31s/it]Validation DataLoader 0:  64%|██████▍   | 48/75 [02:12<00:31,  1.16s/it]Validation DataLoader 0:  64%|██████▍   | 48/75 [02:12<00:31,  1.16s/it]Validation DataLoader 0:  65%|██████▌   | 49/75 [02:13<00:27,  1.06s/it]Validation DataLoader 0:  65%|██████▌   | 49/75 [02:13<00:27,  1.06s/it]Validation DataLoader 0:  67%|██████▋   | 50/75 [02:14<00:24,  1.03it/s]Validation DataLoader 0:  67%|██████▋   | 50/75 [02:14<00:24,  1.03it/s]Validation DataLoader 0:  68%|██████▊   | 51/75 [02:16<00:32,  1.37s/it]Validation DataLoader 0:  68%|██████▊   | 51/75 [02:16<00:32,  1.37s/it]Validation DataLoader 0:  69%|██████▉   | 52/75 [02:18<00:37,  1.63s/it]Validation DataLoader 0:  69%|██████▉   | 52/75 [02:18<00:37,  1.63s/it]Validation DataLoader 0:  71%|███████   | 53/75 [02:21<00:42,  1.94s/it]Validation DataLoader 0:  71%|███████   | 53/75 [02:21<00:42,  1.94s/it]Validation DataLoader 0:  72%|███████▏  | 54/75 [02:23<00:42,  2.02s/it]Validation DataLoader 0:  72%|███████▏  | 54/75 [02:23<00:42,  2.02s/it]Validation DataLoader 0:  73%|███████▎  | 55/75 [02:25<00:41,  2.10s/it]Validation DataLoader 0:  73%|███████▎  | 55/75 [02:25<00:41,  2.10s/it]Validation DataLoader 0:  75%|███████▍  | 56/75 [02:28<00:44,  2.37s/it]Validation DataLoader 0:  75%|███████▍  | 56/75 [02:28<00:44,  2.37s/it]Validation DataLoader 0:  76%|███████▌  | 57/75 [02:30<00:39,  2.20s/it]Validation DataLoader 0:  76%|███████▌  | 57/75 [02:30<00:39,  2.20s/it]Validation DataLoader 0:  77%|███████▋  | 58/75 [02:32<00:35,  2.10s/it]Validation DataLoader 0:  77%|███████▋  | 58/75 [02:32<00:35,  2.10s/it]Validation DataLoader 0:  79%|███████▊  | 59/75 [02:35<00:35,  2.21s/it]Validation DataLoader 0:  79%|███████▊  | 59/75 [02:35<00:35,  2.21s/it]Validation DataLoader 0:  80%|████████  | 60/75 [02:37<00:33,  2.22s/it]Validation DataLoader 0:  80%|████████  | 60/75 [02:37<00:33,  2.22s/it]Validation DataLoader 0:  81%|████████▏ | 61/75 [02:39<00:29,  2.08s/it]Validation DataLoader 0:  81%|████████▏ | 61/75 [02:39<00:29,  2.08s/it]Validation DataLoader 0:  83%|████████▎ | 62/75 [02:41<00:28,  2.22s/it]Validation DataLoader 0:  83%|████████▎ | 62/75 [02:41<00:28,  2.22s/it]Validation DataLoader 0:  84%|████████▍ | 63/75 [02:43<00:26,  2.18s/it]Validation DataLoader 0:  84%|████████▍ | 63/75 [02:43<00:26,  2.18s/it]Validation DataLoader 0:  85%|████████▌ | 64/75 [02:45<00:24,  2.19s/it]Validation DataLoader 0:  85%|████████▌ | 64/75 [02:45<00:24,  2.19s/it]Validation DataLoader 0:  87%|████████▋ | 65/75 [02:47<00:19,  1.96s/it]Validation DataLoader 0:  87%|████████▋ | 65/75 [02:47<00:19,  1.96s/it]Validation DataLoader 0:  88%|████████▊ | 66/75 [02:49<00:18,  2.05s/it]Validation DataLoader 0:  88%|████████▊ | 66/75 [02:49<00:18,  2.05s/it]Validation DataLoader 0:  89%|████████▉ | 67/75 [02:51<00:15,  1.94s/it]Validation DataLoader 0:  89%|████████▉ | 67/75 [02:51<00:15,  1.94s/it]Validation DataLoader 0:  91%|█████████ | 68/75 [02:53<00:14,  2.07s/it]Validation DataLoader 0:  91%|█████████ | 68/75 [02:53<00:14,  2.07s/it]Validation DataLoader 0:  92%|█████████▏| 69/75 [02:55<00:12,  2.07s/it]Validation DataLoader 0:  92%|█████████▏| 69/75 [02:55<00:12,  2.07s/it]Validation DataLoader 0:  93%|█████████▎| 70/75 [02:57<00:09,  1.99s/it]Validation DataLoader 0:  93%|█████████▎| 70/75 [02:57<00:09,  1.99s/it]Validation DataLoader 0:  95%|█████████▍| 71/75 [03:00<00:09,  2.40s/it]Validation DataLoader 0:  95%|█████████▍| 71/75 [03:00<00:09,  2.40s/it]Validation DataLoader 0:  96%|█████████▌| 72/75 [03:03<00:07,  2.48s/it]Validation DataLoader 0:  96%|█████████▌| 72/75 [03:03<00:07,  2.48s/it]Validation DataLoader 0:  97%|█████████▋| 73/75 [03:05<00:04,  2.40s/it]Validation DataLoader 0:  97%|█████████▋| 73/75 [03:05<00:04,  2.40s/it]Validation DataLoader 0:  99%|█████████▊| 74/75 [03:08<00:02,  2.57s/it]Validation DataLoader 0:  99%|█████████▊| 74/75 [03:08<00:02,  2.57s/it]Validation DataLoader 0: 100%|██████████| 75/75 [03:11<00:00,  2.54s/it]Validation DataLoader 0: 100%|██████████| 75/75 [03:11<00:00,  2.54s/it]Validation results saved to /n/fs/nlp-abiramg/NLProofS/prover/lightning_logs/version_19005072/results_val.json and /n/fs/nlp-abiramg/NLProofS/prover/lightning_logs/version_19005072/results_val.tsv

  0%|          | 0/150 [00:00<?, ?it/s][A100%|██████████| 150/150 [00:00<00:00, 3982.94it/s]
Performance by depth:
53 trees have depth 1
	leaves: 0.8301886792452831	0.9320754716981133
	steps: 0.8301886792452831	0.8773584905660378
	proof: 0.8301886792452831	0.8301886792452831
22 trees have depth 2
	leaves: 0.6363636363636364	0.9017316017316017
	steps: 0.6363636363636364	0.75
	proof: 0.6363636363636364	0.6363636363636364
23 trees have depth 3
	leaves: 0.4782608695652174	0.8877156659765355
	steps: 0.391304347826087	0.5805383022774326
	proof: 0.391304347826087	0.391304347826087
41 trees have depth 4
	leaves: 0.34146341463414637	0.8179562984441033
	steps: 0.17073170731707318	0.4127951993805653
	proof: 0.17073170731707318	0.17073170731707318
11 trees have depth 5
	leaves: 0.2727272727272727	0.887386098749735
	steps: 0.09090909090909091	0.41914600550964193
	proof: 0.09090909090909091	0.09090909090909091
Performance by size:
53 trees have size 3
	leaves: 0.8301886792452831	0.9320754716981133
	steps: 0.8301886792452831	0.8773584905660378
	proof: 0.8301886792452831	0.8301886792452831
15 trees have size 5
	leaves: 0.6	0.8825396825396826
	steps: 0.6	0.7666666666666667
	proof: 0.6	0.6
7 trees have size 6
	leaves: 0.7142857142857143	0.9428571428571428
	steps: 0.7142857142857143	0.7142857142857143
	proof: 0.7142857142857143	0.7142857142857143
13 trees have size 7
	leaves: 0.5384615384615384	0.8945665445665445
	steps: 0.38461538461538464	0.5399267399267399
	proof: 0.38461538461538464	0.38461538461538464
6 trees have size 8
	leaves: 0.3333333333333333	0.9027777777777777
	steps: 0.3333333333333333	0.6555555555555556
	proof: 0.3333333333333333	0.3333333333333333
23 trees have size 9
	leaves: 0.5217391304347826	0.9149758454106282
	steps: 0.2608695652173913	0.5158385093167702
	proof: 0.2608695652173913	0.2608695652173913
3 trees have size 10
	leaves: 0.3333333333333333	0.6666666666666666
	steps: 0.3333333333333333	0.3333333333333333
	proof: 0.3333333333333333	0.3333333333333333
24 trees have size 11
	leaves: 0.20833333333333334	0.7917323417323416
	steps: 0.08333333333333333	0.340707671957672
	proof: 0.08333333333333333	0.08333333333333333
2 trees have size 12
	leaves: 0.5	0.9615384615384615
	steps: 0.5	0.7222222222222222
	proof: 0.5	0.5
2 trees have size 13
	leaves: 0.0	0.8221153846153846
	steps: 0.0	0.6136363636363635
	proof: 0.0	0.0
1 trees have size 17
	leaves: 0.0	0.22222222222222224
	steps: 0.0	0.0
	proof: 0.0	0.0
1 trees have size 19
	leaves: 0.0	0.8333333333333334
	steps: 0.0	0.2222222222222222
	proof: 0.0	0.0
Validation DataLoader 0: 100%|██████████| 75/75 [03:11<00:00,  2.55s/it]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  ExactMatch_leaves_val     0.5733333333333334
  ExactMatch_proof_val              0.5
  ExactMatch_steps_val              0.5
      F1_leaves_val         0.8863534058534056
      F1_proof_val                  0.5
      F1_steps_val          0.6525839345839346
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Configuration: 
 Namespace(config=None, subcommand='validate', validate=Namespace(config=[Path_fsr(scone_validate.yaml, cwd=/n/fs/nlp-abiramg/NLProofS/prover)], seed_everything=1, trainer=Namespace(logger=True, checkpoint_callback=None, enable_checkpointing=True, callbacks=[Namespace(class_path='pytorch_lightning.callbacks.LearningRateMonitor', init_args=Namespace(logging_interval='step', log_momentum=False))], default_root_dir=None, gradient_clip_val=0.5, gradient_clip_algorithm=None, process_position=0, num_nodes=1, num_processes=None, devices=None, gpus=1, auto_select_gpus=False, tpu_cores=None, ipus=None, log_gpu_memory=None, progress_bar_refresh_rate=None, enable_progress_bar=True, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=10, fast_dev_run=False, accumulate_grad_batches=32, max_epochs=600, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, val_check_interval=None, flush_logs_every_n_steps=None, log_every_n_steps=5, accelerator=None, strategy=None, sync_batchnorm=False, precision=32, enable_model_summary=True, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, resume_from_checkpoint=None, profiler=None, benchmark=None, deterministic=False, reload_dataloaders_every_n_epochs=0, auto_lr_find=False, replace_sampler_ddp=True, detect_anomaly=False, auto_scale_batch_size=False, prepare_data_per_node=None, plugins=None, amp_backend='native', amp_level=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False, terminate_on_nan=None), model=Namespace(stepwise=True, max_num_steps=20, model_name='t5-large', lr=5e-05, warmup_steps=1000, diversity_penalty=0, num_beam_groups=1, num_beams=10, topk=10, proof_search=True, verifier_weight=0.5, verifier_ckpt='../verifier/lightning_logs/scone_verifier/checkpoints/epoch=49-step=21150.ckpt', oracle_prover=False, oracle_verifier=False, log_name='', dataset='entailmentbank', max_input_len=1024), data=Namespace(dataset='entailmentbank', sample_goal='intermediates', max_input_len=1024, max_output_len=64, batch_size=2, num_workers=2, path_train='../data/train_scone.jsonl', path_val='../data/dev_scone.jsonl', path_test='../data/test_scone.jsonl', subtree_proved_prob=0.75, subtree_proved_all_or_none=False, model_name='t5-large', stepwise=True), log_name='', ckpt_path='./lightning_logs/scone_prover_train/checkpoints/epoch=499-step=5000.ckpt', verbose=True))
