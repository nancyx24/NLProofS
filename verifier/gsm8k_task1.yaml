seed_everything: 1
trainer:
  gpus: 1
  max_epochs: 50
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
model:
  lr: 1e-5
  warmup_steps: 2000
  model_name: roberta-large
  pos_weight: 128.0
data:
  dataset: entailmentbank
  batch_size: 32
  num_workers: 2
  max_num_premises: 4
  max_input_len: 256
  irrelevant_distractors_only: false
  path_train: ../data/train_gsm8k.jsonl
  path_val: ../data/dev_gsm8k.jsonl
